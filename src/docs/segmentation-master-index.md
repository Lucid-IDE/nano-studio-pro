# üéØ Advanced Segmentation App Design - Master Index & RAG Documentation

## üìã Table of Contents

### üèóÔ∏è **SYSTEM ARCHITECTURE**
- [1.1 Core Architecture Overview](#11-core-architecture-overview)
- [1.2 Three-Tier Design Pattern](#12-three-tier-design-pattern)
- [1.3 Modular Component System](#13-modular-component-system)
- [1.4 Performance Optimization Framework](#14-performance-optimization-framework)

### ü™Ñ **MAGIC WAND TOOL**
- [2.1 Algorithm Framework](#21-algorithm-framework)
- [2.2 Color Matching Systems](#22-color-matching-systems)
- [2.3 Texture Analysis Engine](#23-texture-analysis-engine)
- [2.4 Search Area Management](#24-search-area-management)
- [2.5 Segmentation Expansion](#25-segmentation-expansion)

### üé£ **INTELLIGENT LASSO TOOL**
- [3.1 Path Algorithm Design](#31-path-algorithm-design)
- [3.2 Node-Based System](#32-node-based-system)
- [3.3 Edge Detection Intelligence](#33-edge-detection-intelligence)
- [3.4 Trajectory Prediction](#34-trajectory-prediction)
- [3.5 Resistance Path Calculation](#35-resistance-path-calculation)

### üåà **ADVANCED COLOR PROCESSING**
- [4.1 Quaternion Color Implementation](#41-quaternion-color-implementation)
- [4.2 Multi-Color Space Analysis](#42-multi-color-space-analysis)
- [4.3 RGB vs HSV vs LAB Comparison](#43-rgb-vs-hsv-vs-lab-comparison)
- [4.4 Color Space Hybridization](#44-color-space-hybridization)

### üé® **USER INTERFACE ARCHITECTURE**
- [5.1 Real-Time Parameter Control](#51-real-time-parameter-control)
- [5.2 Value Drawer Analytics](#52-value-drawer-analytics)
- [5.3 Visual Feedback Systems](#53-visual-feedback-systems)
- [5.4 Preset Configuration System](#54-preset-configuration-system)

### ‚ö° **PERFORMANCE & OPTIMIZATION**
- [6.1 Adaptive Processing](#61-adaptive-processing)
- [6.2 Multi-Threading Architecture](#62-multi-threading-architecture)
- [6.3 Memory Management](#63-memory-management)
- [6.4 GPU Acceleration](#64-gpu-acceleration)

### üõ†Ô∏è **IMPLEMENTATION ROADMAP**
- [7.1 Phase 1: Core Engine](#71-phase-1-core-engine)
- [7.2 Phase 2: Advanced Features](#72-phase-2-advanced-features)
- [7.3 Phase 3: Optimization](#73-optimization)
- [7.4 Phase 4: Intelligence](#74-intelligence)

### üîß **ADVANCED FEATURES**
- [8.1 Auto-Detection Mode](#81-auto-detection-mode)
- [8.2 Multi-Node Line Draw](#82-multi-node-line-draw)
- [8.3 Soft Edge Handling](#83-soft-edge-handling)
- [8.4 Vectorization Pipeline](#84-vectorization-pipeline)
- [8.5 Background-Sampled Translucency](#85-background-sampled-translucency)
- [8.6 Advanced Magic Lasso Features](#86-advanced-magic-lasso-features)
- [8.7 Cursor Location Zoom Preview System](#87-cursor-location-zoom-preview-system)

### üìä **TECHNICAL SPECIFICATIONS**
- [9.1 Algorithm Parameters](#91-algorithm-parameters)
- [9.2 UI Component Specifications](#92-ui-component-specifications)
- [9.3 Data Structures](#93-data-structures)
- [9.4 API Interfaces](#94-api-interfaces)

---

## üè∑Ô∏è **MASTER TAG INDEX**

### **Algorithm Tags**
- `#algorithm:magic-wand` - Magic Wand tool implementation
- `#algorithm:lasso` - Intelligent Lasso tool
- `#algorithm:flood-fill` - Region growing algorithms
- `#algorithm:edge-detection` - Edge detection methods
- `#algorithm:texture-analysis` - Texture processing algorithms
- `#algorithm:quaternion` - Quaternion color processing
- `#algorithm:gabor` - Gabor filter implementation
- `#algorithm:lbp` - Local Binary Pattern analysis
- `#algorithm:region-growing` - Connected component analysis
- `#algorithm:watershed` - Watershed segmentation
- `#algorithm:graph-cuts` - Graph-based segmentation
- `#algorithm:mean-shift` - Mean shift clustering
- `#algorithm:live-wire` - Live-wire pathfinding
- `#algorithm:alpha-matting` - Alpha matting techniques
- `#algorithm:vectorization` - Vectorization algorithms

### **Color Space Tags**
- `#colorspace:rgb` - RGB color space processing
- `#colorspace:hsv` - HSV color space processing
- `#colorspace:lab` - LAB color space processing
- `#colorspace:quaternion` - Quaternion color representation
- `#colorspace:hybrid` - Hybrid color space approaches

### **UI Component Tags**
- `#ui:toolbar` - Toolbar components
- `#ui:drawer` - Drawer/panel components
- `#ui:canvas` - Canvas interaction
- `#ui:settings` - Settings panels
- `#ui:presets` - Preset management
- `#ui:feedback` - Visual feedback systems
- `#ui:analytics` - Analytics displays

### **Performance Tags**
- `#performance:gpu` - GPU acceleration
- `#performance:multithreading` - Multi-threading
- `#performance:memory` - Memory management
- `#performance:optimization` - Performance optimization
- `#performance:caching` - Caching strategies

### **Feature Tags**
- `#feature:auto-detect` - Auto-detection capabilities
- `#feature:multi-node` - Multi-node sampling
- `#feature:soft-edges` - Soft edge handling
- `#feature:vectorization` - Vectorization features
- `#feature:translucency` - Translucency effects
- `#feature:avoidance` - Avoidance ranges
- `#feature:adaptive` - Adaptive processing
- `#feature:predictive-segmentation` - Predictive hover segmentation
- `#feature:trajectory-prediction` - Future trajectory prediction
- `#feature:perpendicular-bias` - Perpendicular snapping bias
- `#feature:jump-optimization` - Jump handling and optimization
- `#feature:cursor-zoom` - Cursor location zoom preview
- `#feature:color-analysis` - Real-time color analysis
- `#feature:pixel-inspection` - Pixel-level inspection tools
- `#feature:gradient-analysis` - Gradient strength analysis

### **Implementation Tags**
- `#impl:javascript` - JavaScript implementation
- `#impl:opencv` - OpenCV integration
- `#impl:webgl` - WebGL rendering
- `#impl:wasm` - WebAssembly modules
- `#impl:typescript` - TypeScript code
- `#impl:react` - React components

### **Research Tags**
- `#research:computer-vision` - Computer vision research
- `#research:image-processing` - Image processing research
- `#research:segmentation` - Segmentation research
- `#research:quaternion` - Quaternion mathematics
- `#research:ui-ux` - UI/UX research

---

## üîç **RAG UTILIZATION INDEX**

### **Query Categories**
1. **Algorithm Implementation Queries**
   - "How to implement magic wand tool?"
   - "What are the best color matching algorithms?"
   - "How does quaternion color processing work?"

2. **Performance Optimization Queries**
   - "How to optimize segmentation performance?"
   - "GPU acceleration strategies for image processing"
   - "Memory management for large images"

3. **UI/UX Design Queries**
   - "Best practices for real-time parameter control"
   - "How to design intuitive segmentation interfaces"
   - "Visual feedback systems for image editing"

4. **Technical Specification Queries**
   - "Parameter ranges for segmentation algorithms"
   - "Data structures for image processing"
   - "API design for modular segmentation"

5. **Feature Implementation Queries**
   - "How to implement auto-detection mode?"
   - "Multi-node sampling techniques"
   - "Soft edge handling algorithms"

### **Semantic Search Vectors**
- **Algorithm Complexity**: Simple ‚Üí Complex
- **Performance Impact**: Low ‚Üí High
- **Implementation Difficulty**: Easy ‚Üí Hard
- **User Impact**: Basic ‚Üí Advanced
- **Research Level**: Established ‚Üí Cutting-edge

---

## üìö **DETAILED SECTIONS**

### 1.1 Core Architecture Overview
**Tags**: `#architecture:core` `#system:design` `#modularity`

The advanced segmentation app follows a sophisticated three-tier architecture:

**Processing Layer**
- Algorithm engines (Magic Wand, Lasso, Texture Analysis)
- Color space processors (RGB, HSV, LAB, Quaternion)
- Performance optimization modules
- GPU acceleration interfaces

**UI Layer**
- Real-time parameter controls
- Visual feedback systems
- Preset management
- Analytics displays

**Data Layer**
- Image data management
- Preset storage
- Configuration persistence
- Performance metrics

**Key Benefits**:
- Modular design enables independent component updates
- Scalable architecture supports feature expansion
- Performance optimization through layer separation
- Maintainable codebase with clear responsibilities

### 2.1 Algorithm Framework
**Tags**: `#algorithm:framework` `#magic-wand` `#segmentation`

The Magic Wand tool implements five distinct algorithm categories:

**Basic Color Matching**
- RGB, HSV, LAB color spaces
- Adjustable tolerance parameters
- Search radius control (1-100 pixels)
- Edge falloff patterns (linear, Gaussian, exponential)

**Advanced Color Analysis**
- Quaternion RGB processing (4D vectors)
- Holistic color channel processing
- Reduced artifacts and better channel coupling
- Illumination invariance

**Texture Analysis**
- Local Binary Patterns (LBP)
- Gabor filters
- Fractal dimension calculations
- Material pattern recognition

**Neighborhood Analysis**
- Connected component analysis
- Region growing algorithms
- Watershed segmentation
- Graph cuts for boundary detection

**Hybrid Methods**
- Multi-scale analysis
- Spectral clustering
- Optional deep learning integration
- Complex scenario handling

### 3.1 Path Algorithm Design
**Tags**: `#lasso:algorithm` `#path:optimization` `#edge:detection` `#predictive:segmentation` `#trajectory:prediction`

The Intelligent Lasso tool implements sophisticated path-following with advanced predictive capabilities:

**Enhanced Node-Based System**
- Configurable drop intervals (50-500ms, default 150ms)
- Distance constraints (1-2px min, 5-10px max)
- Intelligent node dropping based on variance detection
- Bezier curve fitting for smooth paths
- Elasticity factors for rubber-band behavior

**Predictive Hover Segmentation**
- Real-time mini-flood segmentation around cursor (15-20px radius)
- Edge detection using Sobel/Canny algorithms
- Future trajectory prediction (10-20px ahead)
- Dynamic tolerance adjustment via mouse scroll

**Advanced Edge Detection Intelligence**
- Real-time edge detection in search areas
- Magnetic snap to boundaries with perpendicular bias
- Parallel edge detection when original disappears
- Color continuity and trajectory prediction
- Dominant angle detection from edge histograms

**Trajectory-Aware Snapping**
- Balances least resistance with perpendicular bias
- Exponential decay for non-perpendicular angles (sigma=20¬∞)
- Perspective-aware adjustments (e.g., 85¬∞ edges with 90¬∞ mouse pull)
- Cost function: `resistance * (1 - perpBias * exp(-(90-diff)¬≤/(2*sigma¬≤)))`

**Path Intelligence Features**
- Color transition handling
- Discontinuity detection
- Alternative path searching
- Context awareness for image structures
- Jump optimization with A* pathfinding
- Mid-draw tolerance tuning

### 4.1 Quaternion Color Implementation
**Tags**: `#quaternion:color` `#4d:processing` `#mathematical:elegance`

Quaternion color processing represents RGB as 4D vectors:

**Mathematical Foundation**
- q = q‚ÇÄ + q‚ÇÅi + q‚ÇÇj + q‚ÇÉk representation
- Quaternion multiplication rules (i¬≤ = j¬≤ = k¬≤ = ijk = -1)
- Rotation operations in color space
- Holistic color channel processing

**Implementation Benefits**
- Artifact reduction in color processing
- Better RGB component coupling
- Rotational invariance under varying lighting
- Mathematical elegance for complex transformations

**Advanced Applications**
- Quaternion Gabor Filters (QGF)
- Color-texture-orientation fusion
- Enhanced edge detection
- Improved segmentation quality

### 5.1 Real-Time Parameter Control
**Tags**: `#ui:realtime` `#parameters:control` `#user:experience`

Dynamic controls that adapt based on selected algorithms:

**Control Features**
- Mouse wheel binding for rapid adjustment
- Keyboard shortcuts for quick access
- Complete undo/redo history
- Context-sensitive parameter display

**Analytics Display**
- Color histograms (RGB, HSV, LAB)
- Texture metrics and pattern analysis
- Pixel counts and coverage areas
- Quality scores and confidence indicators

**Visual Feedback**
- Marching ants with customizable speed
- Color coding for selection types
- Transparency controls for overlay adjustment
- Real-time preview updates

### 6.1 Adaptive Processing
**Tags**: `#performance:adaptive` `#optimization:dynamic` `#resource:management`

Intelligent algorithm selection based on context:

**Adaptive Features**
- Image complexity assessment
- Computational resource evaluation
- Quality scaling for real-time performance
- Intelligent caching systems

**Multi-Threading Architecture**
- CPU core workload distribution
- Optional GPU acceleration (OpenCL, CUDA)
- Hybrid CPU-GPU optimization
- Algorithm-specific performance tuning

**Memory Management**
- Efficient data structures
- Streaming processing for large images
- Automatic garbage collection
- Memory usage optimization

### 8.1 Auto-Detection Mode
**Tags**: `#feature:auto-detect` `#intelligence:adaptive` `#presets:dynamic`

Intelligent hover system with pre-built datasets:

**Detection Capabilities**
- Skin tone detection (HSV ranges)
- Green screen identification
- Texture pattern recognition
- Material classification

**Auto-Tuning Features**
- Dynamic parameter adjustment
- Tolerance optimization
- Color space selection
- Texture threshold adaptation

**Implementation**
- JSON-based preset storage
- Real-time ROI analysis
- Feature extraction (histograms, GLCM, LBP)
- Confidence scoring and matching

### 8.2 Multi-Node Line Draw
**Tags**: `#feature:multi-node` `#sampling:variant` `#hybrid:approach`

Variant-aware search through line drawing:

**Node Dropping System**
- Time-based intervals (100ms default)
- Distance-based constraints (3-5px min/max)
- High-variance spot detection
- Automatic feature aggregation

**Aggregation Methods**
- Union ranges for color tolerance
- Average feature computation
- Cluster-based merging
- Dynamic tolerance calculation

**Benefits**
- Handles shading variations
- Bridges color transitions
- Reduces manual adjustment
- Improves segmentation accuracy

### 8.3 Soft Edge Handling
**Tags**: `#feature:soft-edges` `#alpha:matting` `#gradient:falloff`

Semi-transparent gradient masks for realistic edges:

**Edge Detection**
- Sobel/Canny edge detection
- Gradient-based alpha computation
- Boundary pixel identification
- Mix ratio calculation

**Alpha Matting**
- Foreground/background separation
- Partial opacity estimation
- Smooth falloff gradients
- Halo artifact prevention

**Implementation**
- Feathering with configurable radius
- Gaussian blur on alpha channel
- Background-sampled translucency
- Real-time preview updates

### 8.4 Vectorization Pipeline
**Tags**: `#feature:vectorization` `#svg:generation` `#curve:optimization`

Intelligent vectorization with edge type detection:

**Edge Analysis**
- Straight line detection (Hough transform)
- Curve vs. straight classification
- Corner detection (Harris detector)
- Sharp vs. rounded edge identification

**Adaptive Fitting**
- Ramer-Douglas-Peucker simplification
- Bezier curve fitting for smooth edges
- Fillet application for rounded corners
- Path optimization for clean SVGs

**Quality Features**
- Contrast enhancement for foggy details
- Linear regression for straightness
- Angle threshold for corner detection
- Auto-radius based on edge strength

### 8.5 Background-Sampled Translucency
**Tags**: `#feature:translucency` `#background:sampling` `#realistic:removal`

Hyper-realistic gradient-based removal:

**Background Sampling**
- Alt-click for BG color extraction
- HSV average + variance calculation
- Tolerance range computation
- Multi-sample support

**Translucency Calculation**
- Mix ratio estimation (FG/BG blend)
- Color distance normalization
- Radial falloff application
- Natural gradient creation

**Benefits**
- Realistic edge transitions
- Halo artifact elimination
- Automatic BG adaptation
- Professional-quality results

### 8.6 Advanced Magic Lasso Features
**Tags**: `#lasso:advanced` `#predictive:segmentation` `#trajectory:prediction` `#perpendicular:bias` `#jump:optimization`

Enhanced Magic Lasso with predictive intelligence and advanced pathfinding:

**Predictive Hover Segmentation**
- Real-time analysis of areas under/ahead of cursor
- Mini-flood segmentation (15-20px radius) for local edges
- Future trajectory prediction (10-20px ahead)
- Dynamic edge detection using Sobel/Canny algorithms

**Trajectory-Aware Snapping**
- Balances least resistance with perpendicular bias
- Exponential decay for non-perpendicular angles (sigma=20¬∞)
- Perspective-aware adjustments (e.g., 85¬∞ edges with 90¬∞ mouse pull)
- Cost function: `resistance * (1 - perpBias * exp(-(90-diff)¬≤/(2*sigma¬≤)))`

**Dynamic Mid-Draw Adjustments**
- Mouse scroll to tune tolerance/strength live
- Real-time re-segmentation of hover/future areas
- Tolerance range: 0-100 with 5-unit increments
- Immediate visual feedback on parameter changes

**Jump Optimization**
- Finer-grained pathfinding between nodes (0.5px grid)
- A* algorithm with image-aware cost functions
- Gradient + perpendicular bias + image values
- Smooth/straight path generation based on edge type

**Advanced Parameter Configuration**
| Parameter | Description | Default | Range |
|-----------|-------------|---------|-------|
| perpBias | Favor perpendicular vs. resistance | 0.8 | 0-1 |
| falloffSigma | Degrees for exponential decay | 20 | 10-50 |
| dropTimeMs | Node time interval | 150 | 50-300 |
| minDropPx | Minimum node distance | 3 | 1-10 |
| maxSegmentPx | Maximum segment length | 10 | 5-20 |
| cornerThresh | Angle threshold for sharp corners | 45 | 30-60 |

**System Architecture**
- **Data Layer**: Path as array of points; nodes as {x, y, features}
- **Algorithm Layer**: Pluggable costs (resistance/perp); A*/Dijkstra for snaps/jumps
- **UI Layer**: ShadCN components; Framer Motion for previews
- **Performance**: Throttled mousemove (16ms for 60fps); WebGPU for heavy graphs

**Dependencies**
- **opencv.js**: Edge detection (Sobel/Canny), angles, variance
- **ramer-douglas-peucker**: Path simplification (curves/straights)
- **potrace**: Optional vector output generation

**Workflows**
1. **Basic Draw**: Mouse down ‚Üí move (hover seg/snaps) ‚Üí up (final mask)
2. **Predictive Pull**: Drag 90¬∞ across parallels ‚Üí snaps perpendicular, predicts ahead
3. **Tune Mid-Draw**: Scroll to refine tolerance ‚Üí live re-snap
4. **Jump Fix**: If disconnect, auto A* connects with image-aware path
5. **Integration**: Works with Magic Wand and auto-detection presets

### 8.7 Cursor Location Zoom Preview System
**Tags**: `#feature:cursor-zoom` `#color:analysis` `#real-time:preview` `#pixel:inspection` `#gradient:analysis`

Advanced cursor location preview with comprehensive color and area analysis:

**Zoom Preview Interface**
- **Cursor Location Display**: Shows exact cursor pixel position
- **Search Area Visualization**: Circle around cursor showing current search radius
- **Zoomed Pixel View**: Square area around cursor zoomed to pixel level
- **Extended Context**: Additional area around search radius for context
- **Real-Time Updates**: Live preview as cursor moves

**Comprehensive Color Analysis**
- **RGB Values**: Direct RGB color values (e.g., R: 76, G: 93, B: 122)
- **Hex Color**: Hexadecimal representation (e.g., #4c5d7a)
- **HSV Values**: Hue, Saturation, Value (e.g., 218¬∞, 38%, 48%)
- **LAB Values**: L*a*b* color space (e.g., L: 39.2, a: 1.3, b: -18.4)
- **Color Space Conversion**: Real-time conversion between all color spaces

**Area Analysis Features**
- **Similarity Percentage**: Bar showing similarity of search area pixels
- **Gradient Strength**: Analysis of color gradients in the area
- **Edge Strength**: Detection of edge intensity and direction
- **Color Space Variances**: Variance analysis across different color spaces

**Color Space Variance Analysis**
| Color Space | Variance | Description |
|-------------|----------|-------------|
| **RGB** | 19.6 | Red, Green, Blue channel variance |
| **HSV** | 0.062 | Hue, Saturation, Value variance |
| **LAB** | 5.1 | L*a*b* perceptual variance |

**UI Components**
- **Drawer Panel**: Expandable drawer showing zoom preview
- **Color Swatches**: Visual color representation
- **Variance Bars**: Graphical representation of color variances
- **Gradient Visualization**: Visual gradient strength indicators
- **Edge Detection Overlay**: Edge strength visualization

**Real-Time Analysis**
- **Live Updates**: All values update in real-time as cursor moves
- **Performance Optimized**: Efficient analysis for smooth cursor tracking
- **Multi-Color Space**: Simultaneous analysis in RGB, HSV, and LAB
- **Contextual Information**: Shows both local and extended area analysis

**Integration with Tools**
- **Magic Wand**: Shows search area and color tolerance
- **Magic Lasso**: Displays edge strength and gradient information
- **Auto-Detection**: Provides color analysis for preset matching
- **Vectorization**: Shows edge information for path optimization

**Technical Implementation**
```javascript
// Cursor Zoom Preview System
class CursorZoomPreview {
  constructor(canvas, drawer) {
    this.canvas = canvas;
    this.drawer = drawer;
    this.zoomLevel = 8; // 8x zoom
    this.searchRadius = 10;
    this.contextRadius = 20;
  }

  updateCursorPosition(x, y) {
    // Update zoom preview
    this.updateZoomPreview(x, y);
    
    // Analyze colors
    const colorAnalysis = this.analyzeColors(x, y);
    
    // Calculate variances
    const variances = this.calculateVariances(x, y);
    
    // Update UI
    this.updateUI(colorAnalysis, variances);
  }

  analyzeColors(x, y) {
    const pixel = this.getPixelColor(x, y);
    return {
      rgb: [pixel.r, pixel.g, pixel.b],
      hex: this.rgbToHex(pixel.r, pixel.g, pixel.b),
      hsv: this.rgbToHsv(pixel.r, pixel.g, pixel.b),
      lab: this.rgbToLab(pixel.r, pixel.g, pixel.b)
    };
  }

  calculateVariances(x, y) {
    const searchArea = this.getSearchArea(x, y, this.searchRadius);
    return {
      rgb: this.calculateRgbVariance(searchArea),
      hsv: this.calculateHsvVariance(searchArea),
      lab: this.calculateLabVariance(searchArea)
    };
  }
}
```

**Benefits**
- **Precise Color Selection**: Exact color values for accurate selection
- **Visual Feedback**: Real-time visual confirmation of cursor position
- **Color Space Comparison**: Compare colors across different color spaces
- **Area Analysis**: Understand local color variations and gradients
- **Edge Detection**: Visual confirmation of edge strength and direction
- **Professional Workflow**: Industry-standard color analysis tools

---

## üîß **IMPLEMENTATION GUIDES**

### JavaScript/TypeScript Implementation
**Tags**: `#impl:javascript` `#impl:typescript` `#code:examples`

```typescript
// Magic Wand Implementation
export class MagicWandTool {
  private tolerance: number = 30;
  private colorSpace: 'rgb' | 'hsv' | 'lab' | 'quaternion' = 'hsv';
  private searchRadius: number = 5;
  
  async segment(imageData: ImageData, x: number, y: number): Promise<ImageData> {
    const seedColor = this.getPixelColor(imageData, x, y);
    const mask = await this.floodFill(imageData, x, y, seedColor);
    return this.postProcess(mask);
  }
  
  private async floodFill(imageData: ImageData, startX: number, startY: number, seedColor: number[]): Promise<ImageData> {
    // Implementation with quaternion support
    const mask = new ImageData(imageData.width, imageData.height);
    const queue = [{x: startX, y: startY}];
    const visited = new Set<string>();
    
    while (queue.length > 0) {
      const {x, y} = queue.shift()!;
      const key = `${x},${y}`;
      
      if (visited.has(key)) continue;
      visited.add(key);
      
      const currentColor = this.getPixelColor(imageData, x, y);
      const distance = this.colorDistance(seedColor, currentColor);
      
      if (distance <= this.tolerance) {
        this.setPixelAlpha(mask, x, y, 255);
        this.addNeighbors(queue, x, y, imageData.width, imageData.height);
      }
    }
    
    return mask;
  }
}
```

### OpenCV.js Integration
**Tags**: `#impl:opencv` `#wasm:integration` `#performance:optimization`

```javascript
// Texture Analysis with OpenCV.js
import cv from '@techstark/opencv-js';

export async function analyzeTexture(imageData, x, y, radius = 10) {
  const roi = extractROI(imageData, x, y, radius);
  const gray = cv.cvtColor(roi, cv.COLOR_RGBA2GRAY);
  
  // Gabor Filter
  const gabor = cv.getGaborKernel(
    new cv.Size(21, 21),
    5, // sigma
    0, // theta
    10, // lambda
    0.5, // gamma
    0, // psi
    cv.CV_32F
  );
  
  const filtered = new cv.Mat();
  cv.filter2D(gray, filtered, cv.CV_8UC1, gabor);
  
  // LBP Analysis
  const lbp = computeLBP(gray);
  
  return {
    gaborResponse: filtered,
    lbpPattern: lbp,
    textureFeatures: extractFeatures(filtered, lbp)
  };
}
```

### React Component Architecture
**Tags**: `#impl:react` `#ui:components` `#state:management`

```tsx
// Segmentation Canvas Component
import React, { useRef, useEffect, useState } from 'react';
import { MagicWandTool, LassoTool } from './tools';

export const SegmentationCanvas: React.FC = () => {
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const [activeTool, setActiveTool] = useState<'wand' | 'lasso'>('wand');
  const [settings, setSettings] = useState({
    tolerance: 30,
    colorSpace: 'hsv',
    autoDetect: true
  });
  
  const handleCanvasClick = async (e: React.MouseEvent) => {
    const canvas = canvasRef.current;
    if (!canvas) return;
    
    const rect = canvas.getBoundingClientRect();
    const x = e.clientX - rect.left;
    const y = e.clientY - rect.top;
    
    if (activeTool === 'wand') {
      const wand = new MagicWandTool(settings);
      const mask = await wand.segment(canvas, x, y);
      applyMask(mask);
    }
  };
  
  return (
    <div className="segmentation-workspace">
      <canvas
        ref={canvasRef}
        onClick={handleCanvasClick}
        className="main-canvas"
      />
      <SettingsPanel settings={settings} onChange={setSettings} />
    </div>
  );
};
```

### Advanced Magic Lasso Implementation
**Tags**: `#impl:javascript` `#lasso:advanced` `#predictive:segmentation` `#trajectory:prediction`

```javascript
// utils/lasso.js - Advanced Magic Lasso Implementation
let drawing = false, path = [], nodes = [], traj = {dx:0, dy:0}, tolerance = 30;
const settings = {
  perpBias: 0.8, 
  falloffSigma: 20, 
  dropTimeMs: 150, 
  minDropPx: 3, 
  maxSegmentPx: 10, 
  cornerThresh: 45
};

// Mouse event handlers
canvas.addEventListener('mousedown', (e) => {
  drawing = true;
  path = [{x: e.offsetX, y: e.offsetY}];
  dropNode(path[0]);
});

canvas.addEventListener('mousemove', throttle((e) => {
  if (!drawing) return;
  path.push({x: e.offsetX, y: e.offsetY});
  updateTrajectory();
  
  // Hover segmentation
  const hoverMask = floodFill(imageData, e.offsetX, e.offsetY, tolerance, true, {radius: 20});
  const edges = detectEdges(hoverMask);
  const domAngle = edgeAngleHist(edges).mode;
  
  // Trajectory-aware snapping
  const mouseAngle = Math.atan2(traj.dy, traj.dx) * 180 / Math.PI;
  const diff = angleDiff(mouseAngle, domAngle);
  const perpCost = settings.perpBias * Math.exp(-Math.pow(90 - diff, 2) / (2 * settings.falloffSigma**2));
  
  const snapPath = findOptimalPath(
    path[path.length-2], 
    path[path.length-1], 
    edges, 
    {perpCost, resistance: 1 - settings.perpBias}
  );
  
  updatePath(snapPath);
  predictFuture(10); // Extrapolate and preview
}, 16));

canvas.addEventListener('mouseup', (e) => {
  drawing = false;
  finalizeMask(); // Compute full segmentation from path/nodes
  path = []; nodes = [];
});

canvas.addEventListener('wheel', (e) => {
  if (drawing) {
    tolerance += e.deltaY > 0 ? -5 : 5;
    tolerance = Math.clamp(tolerance, 0, 100);
    reSegHover(); // Re-run hover segmentation with new tolerance
  }
});

// Node dropping with intelligent variance detection
function dropNode(pt) {
  nodes.push({
    x: pt.x, 
    y: pt.y, 
    features: computeFeatures(imageData, pt.x, pt.y)
  });
  
  if (gapToLastNode()) {
    connectJump(nodes[nodes.length-2], nodes[nodes.length-1]);
  }
}

// Trajectory calculation
function updateTrajectory() {
  if (path.length >= 3) {
    const recent = path.slice(-3);
    traj.dx = (recent[2].x - recent[0].x) / 2;
    traj.dy = (recent[2].y - recent[0].y) / 2;
  }
}

// Future prediction
function predictFuture(distance) {
  const futureX = path[path.length-1].x + traj.dx * distance;
  const futureY = path[path.length-1].y + traj.dy * distance;
  const futureMask = floodFill(imageData, futureX, futureY, tolerance, true);
  const futureEdges = extractEdges(futureMask);
  previewFuture(futureEdges);
}

// Jump optimization with A* pathfinding
function connectJump(node1, node2) {
  const fineGrid = createFineGrid(node1, node2, 0.5);
  const optimalPath = aStar(fineGrid, node1, node2, {
    cost: (p1, p2) => {
      const gradient = gradientCost(p1, p2);
      const perp = perpendicularCost(p1, p2, traj);
      const image = imageSimilarityCost(p1, p2);
      return gradient + perp + image;
    }
  });
  return smoothPath(optimalPath, settings.curve);
}

// Edge detection with OpenCV.js
async function detectEdges(mask) {
  const gray = cv.cvtColor(mask, cv.COLOR_RGBA2GRAY);
  const edges = new cv.Mat();
  cv.Canny(gray, edges, 50, 150);
  
  const angles = new cv.Mat();
  cv.Sobel(gray, angles, cv.CV_32F, 1, 1);
  
  return {
    edges: edges,
    angles: angles,
    histogram: computeAngleHistogram(angles)
  };
}

// Perpendicular bias calculation
function perpendicularCost(p1, p2, trajectory) {
  const edgeAngle = Math.atan2(p2.y - p1.y, p2.x - p1.x) * 180 / Math.PI;
  const trajAngle = Math.atan2(trajectory.dy, trajectory.dx) * 180 / Math.PI;
  const diff = Math.min(Math.abs(edgeAngle - trajAngle), 180 - Math.abs(edgeAngle - trajAngle));
  
  return settings.perpBias * Math.exp(-Math.pow(90 - diff, 2) / (2 * settings.falloffSigma**2));
}

// Utility functions
function throttle(func, delay) {
  let timeoutId;
  let lastExecTime = 0;
  return function (...args) {
    const currentTime = Date.now();
    if (currentTime - lastExecTime > delay) {
      func.apply(this, args);
      lastExecTime = currentTime;
    } else {
      clearTimeout(timeoutId);
      timeoutId = setTimeout(() => {
        func.apply(this, args);
        lastExecTime = Date.now();
      }, delay - (currentTime - lastExecTime));
    }
  };
}

function angleDiff(angle1, angle2) {
  let diff = Math.abs(angle1 - angle2);
  return Math.min(diff, 360 - diff);
}

function Math.clamp(value, min, max) {
  return Math.min(Math.max(value, min), max);
}
```

### Cursor Zoom Preview Implementation
**Tags**: `#impl:javascript` `#cursor:zoom` `#color:analysis` `#real-time:preview`

```javascript
// Cursor Zoom Preview System - Complete Implementation
class CursorZoomPreview {
  constructor(canvas, drawer) {
    this.canvas = canvas;
    this.drawer = drawer;
    this.zoomLevel = 8; // 8x zoom
    this.searchRadius = 10;
    this.contextRadius = 20;
    this.isActive = false;
    
    this.setupEventListeners();
    this.initializeUI();
  }

  setupEventListeners() {
    this.canvas.addEventListener('mousemove', (e) => {
      if (this.isActive) {
        this.updateCursorPosition(e.offsetX, e.offsetY);
      }
    });
    
    // Keyboard shortcuts
    document.addEventListener('keydown', (e) => {
      if (e.key === 'z' && !e.ctrlKey && !e.shiftKey && !e.altKey) {
        this.toggleZoomPreview();
      }
    });
  }

  initializeUI() {
    this.drawer.innerHTML = `
      <div class="cursor-zoom-panel">
        <div class="zoom-preview">
          <canvas id="zoomCanvas" width="200" height="200"></canvas>
        </div>
        <div class="color-analysis">
          <div class="color-values">
            <div class="rgb-values">
              <span class="label">RGB:</span>
              <span class="value" id="rgbValue">0, 0, 0</span>
            </div>
            <div class="hex-value">
              <span class="label">Hex:</span>
              <span class="value" id="hexValue">#000000</span>
            </div>
            <div class="hsv-values">
              <span class="label">HSV:</span>
              <span class="value" id="hsvValue">0¬∞, 0%, 0%</span>
            </div>
            <div class="lab-values">
              <span class="label">LAB:</span>
              <span class="value" id="labValue">0, 0, 0</span>
            </div>
          </div>
          <div class="variance-analysis">
            <div class="variance-bars">
              <div class="variance-item">
                <span class="label">RGB Variance:</span>
                <div class="bar">
                  <div class="fill" id="rgbVarianceBar"></div>
                  <span class="value" id="rgbVarianceValue">0.0</span>
                </div>
              </div>
              <div class="variance-item">
                <span class="label">HSV Variance:</span>
                <div class="bar">
                  <div class="fill" id="hsvVarianceBar"></div>
                  <span class="value" id="hsvVarianceValue">0.0</span>
                </div>
              </div>
              <div class="variance-item">
                <span class="label">LAB Variance:</span>
                <div class="bar">
                  <div class="fill" id="labVarianceBar"></div>
                  <span class="value" id="labVarianceValue">0.0</span>
                </div>
              </div>
            </div>
          </div>
          <div class="gradient-analysis">
            <div class="gradient-strength">
              <span class="label">Gradient Strength:</span>
              <div class="indicator" id="gradientIndicator"></div>
            </div>
            <div class="edge-strength">
              <span class="label">Edge Strength:</span>
              <div class="indicator" id="edgeIndicator"></div>
            </div>
          </div>
        </div>
      </div>
    `;
  }

  updateCursorPosition(x, y) {
    // Update zoom preview
    this.updateZoomPreview(x, y);
    
    // Analyze colors
    const colorAnalysis = this.analyzeColors(x, y);
    
    // Calculate variances
    const variances = this.calculateVariances(x, y);
    
    // Calculate gradient and edge strength
    const analysis = this.calculateGradientAndEdge(x, y);
    
    // Update UI
    this.updateUI(colorAnalysis, variances, analysis);
  }

  updateZoomPreview(x, y) {
    const zoomCanvas = document.getElementById('zoomCanvas');
    const ctx = zoomCanvas.getContext('2d');
    
    // Clear canvas
    ctx.clearRect(0, 0, zoomCanvas.width, zoomCanvas.height);
    
    // Get image data around cursor
    const imageData = this.getImageDataAround(x, y, this.contextRadius);
    
    // Draw zoomed preview
    ctx.putImageData(imageData, 0, 0);
    
    // Draw search radius circle
    const centerX = zoomCanvas.width / 2;
    const centerY = zoomCanvas.height / 2;
    const searchRadiusPx = (this.searchRadius / this.contextRadius) * (zoomCanvas.width / 2);
    
    ctx.strokeStyle = '#00ff00';
    ctx.lineWidth = 2;
    ctx.beginPath();
    ctx.arc(centerX, centerY, searchRadiusPx, 0, 2 * Math.PI);
    ctx.stroke();
    
    // Draw cursor crosshair
    ctx.strokeStyle = '#ff0000';
    ctx.lineWidth = 1;
    ctx.beginPath();
    ctx.moveTo(centerX - 5, centerY);
    ctx.lineTo(centerX + 5, centerY);
    ctx.moveTo(centerX, centerY - 5);
    ctx.lineTo(centerX, centerY + 5);
    ctx.stroke();
  }

  analyzeColors(x, y) {
    const pixel = this.getPixelColor(x, y);
    return {
      rgb: [pixel.r, pixel.g, pixel.b],
      hex: this.rgbToHex(pixel.r, pixel.g, pixel.b),
      hsv: this.rgbToHsv(pixel.r, pixel.g, pixel.b),
      lab: this.rgbToLab(pixel.r, pixel.g, pixel.b)
    };
  }

  calculateVariances(x, y) {
    const searchArea = this.getSearchArea(x, y, this.searchRadius);
    return {
      rgb: this.calculateRgbVariance(searchArea),
      hsv: this.calculateHsvVariance(searchArea),
      lab: this.calculateLabVariance(searchArea)
    };
  }

  calculateGradientAndEdge(x, y) {
    const area = this.getSearchArea(x, y, this.searchRadius);
    return {
      gradientStrength: this.calculateGradientStrength(area),
      edgeStrength: this.calculateEdgeStrength(area)
    };
  }

  updateUI(colorAnalysis, variances, analysis) {
    // Update color values
    document.getElementById('rgbValue').textContent = 
      `${colorAnalysis.rgb[0]}, ${colorAnalysis.rgb[1]}, ${colorAnalysis.rgb[2]}`;
    document.getElementById('hexValue').textContent = colorAnalysis.hex;
    document.getElementById('hsvValue').textContent = 
      `${colorAnalysis.hsv[0]}¬∞, ${colorAnalysis.hsv[1]}%, ${colorAnalysis.hsv[2]}%`;
    document.getElementById('labValue').textContent = 
      `${colorAnalysis.lab[0]}, ${colorAnalysis.lab[1]}, ${colorAnalysis.lab[2]}`;
    
    // Update variance bars
    this.updateVarianceBar('rgbVarianceBar', 'rgbVarianceValue', variances.rgb);
    this.updateVarianceBar('hsvVarianceBar', 'hsvVarianceValue', variances.hsv);
    this.updateVarianceBar('labVarianceBar', 'labVarianceValue', variances.lab);
    
    // Update gradient and edge indicators
    this.updateIndicator('gradientIndicator', analysis.gradientStrength);
    this.updateIndicator('edgeIndicator', analysis.edgeStrength);
  }

  updateVarianceBar(barId, valueId, variance) {
    const bar = document.getElementById(barId);
    const value = document.getElementById(valueId);
    
    const percentage = Math.min(variance / 50, 1) * 100; // Normalize to 0-100%
    bar.style.width = `${percentage}%`;
    value.textContent = variance.toFixed(1);
    
    // Color based on variance level
    if (variance < 10) {
      bar.style.backgroundColor = '#00ff00'; // Green for low variance
    } else if (variance < 25) {
      bar.style.backgroundColor = '#ffff00'; // Yellow for medium variance
    } else {
      bar.style.backgroundColor = '#ff0000'; // Red for high variance
    }
  }

  updateIndicator(indicatorId, strength) {
    const indicator = document.getElementById(indicatorId);
    const percentage = Math.min(strength / 100, 1) * 100;
    
    indicator.style.width = `${percentage}%`;
    
    // Color based on strength
    if (strength < 30) {
      indicator.style.backgroundColor = '#00ff00'; // Green for low strength
    } else if (strength < 70) {
      indicator.style.backgroundColor = '#ffff00'; // Yellow for medium strength
    } else {
      indicator.style.backgroundColor = '#ff0000'; // Red for high strength
    }
  }

  toggleZoomPreview() {
    this.isActive = !this.isActive;
    this.drawer.style.display = this.isActive ? 'block' : 'none';
    
    if (this.isActive) {
      console.log('Cursor zoom preview activated');
    } else {
      console.log('Cursor zoom preview deactivated');
    }
  }

  // Utility functions
  rgbToHex(r, g, b) {
    return `#${((1 << 24) + (r << 16) + (g << 8) + b).toString(16).slice(1)}`;
  }

  rgbToHsv(r, g, b) {
    r /= 255; g /= 255; b /= 255;
    const max = Math.max(r, g, b);
    const min = Math.min(r, g, b);
    const diff = max - min;
    
    let h = 0;
    if (diff !== 0) {
      if (max === r) h = ((g - b) / diff) % 6;
      else if (max === g) h = (b - r) / diff + 2;
      else h = (r - g) / diff + 4;
    }
    h = Math.round(h * 60);
    if (h < 0) h += 360;
    
    const s = max === 0 ? 0 : diff / max;
    const v = max;
    
    return [h, Math.round(s * 100), Math.round(v * 100)];
  }

  rgbToLab(r, g, b) {
    // Simplified LAB conversion (in production, use proper color space conversion)
    const l = 0.299 * r + 0.587 * g + 0.114 * b;
    const a = (r - l) * 0.5;
    const b_lab = (b - l) * 0.5;
    
    return [l.toFixed(1), a.toFixed(1), b_lab.toFixed(1)];
  }

  calculateRgbVariance(area) {
    // Calculate RGB variance in the search area
    let sumR = 0, sumG = 0, sumB = 0;
    let sumRSq = 0, sumGSq = 0, sumBSq = 0;
    const count = area.length;
    
    area.forEach(pixel => {
      sumR += pixel.r; sumG += pixel.g; sumB += pixel.b;
      sumRSq += pixel.r * pixel.r;
      sumGSq += pixel.g * pixel.g;
      sumBSq += pixel.b * pixel.b;
    });
    
    const meanR = sumR / count;
    const meanG = sumG / count;
    const meanB = sumB / count;
    
    const varianceR = (sumRSq / count) - (meanR * meanR);
    const varianceG = (sumGSq / count) - (meanG * meanG);
    const varianceB = (sumBSq / count) - (meanB * meanB);

    return (varianceR + varianceG + varianceB) / 3;
  }

  calculateGradientStrength(area) {
    // Calculate gradient strength using Sobel operator
    let totalGradient = 0;
    for (let i = 1; i < area.length - 1; i++) {
      const gx = Math.abs(area[i + 1].r - area[i - 1].r);
      const gy = Math.abs(area[i + 1].g - area[i - 1].g);
      totalGradient += Math.sqrt(gx * gx + gy * gy);
    }
    return totalGradient / area.length;
  }

  calculateEdgeStrength(area) {
    // Calculate edge strength using edge detection
    let edgeStrength = 0;
    for (let i = 0; i < area.length; i++) {
      const pixel = area[i];
      const intensity = (pixel.r + pixel.g + pixel.b) / 3;
      edgeStrength += intensity;
    }
    return edgeStrength / area.length;
  }
}

// Usage example
const cursorZoom = new CursorZoomPreview(canvas, document.getElementById('drawer'));
```